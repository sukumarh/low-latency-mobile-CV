# Low Latency Deep Learning on Smartphones
In this project, we empirically evaluate the performance of two mobile DL frameworks TensorFlow Lite and CoreML , on the inference performance on Android and iOS devices, respectively, using various Convolution Neural Network Architectures.

### Frameworks
1. [TensorFlow Lite](https://www.tensorflow.org/lite) (for Android)
2. [CoreML](https://developer.apple.com/documentation/coreml) (for iOS)

### On-board devices and API Support:
1. CPU:
    - [XNNPack Optimized](https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html) [TF Lite, Android]
2. GPU
3. Apple Neural Network (ANE) [CoreML, iOS]
4. [Neural Network API](https://www.tensorflow.org/lite/performance/nnapi) (NNAPI) [TF Lite, Android]

### Environments
1. [Xcode](https://developer.apple.com/xcode/ide/)
2. [Android Studio](https://developer.android.com/studio)
3. [Qualcomm Snapdragon Profiler](https://developer.qualcomm.com/software/snapdragon-profiler)
